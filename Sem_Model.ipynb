{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39afdd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load necessary libraries...\n",
    "import graphviz\n",
    "import semopy as sem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from semopy import Model, Optimizer\n",
    "import semopy.plot as semplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5586809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = pd.read_excel(r\"C:\\Users\\pc726\\OneDrive\\Desktop\\Final\\survey_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52f07ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', '1. Gender', '2. Age Group', '3. Qualification',\n",
       "       '4. Professional Year ',\n",
       "       '5. How would you rate your digital literacy skills?',\n",
       "       '6. Which social media platforms do you use for academic purposes? (Select all that apply)',\n",
       "       '7. How frequently do you use social media for academic purposes?',\n",
       "       '8. What type of academic content do you access on social media? (Select all that apply)',\n",
       "       '9. Do you think social media helps improve your academic performance?',\n",
       "       '10. How does social media benefit your medical education? (Select all that apply)',\n",
       "       '11. Do you think social media is more effective than traditional learning methods (books, lectures)?',\n",
       "       '12. Why do you prefer social media over traditional sources? (Select all that apply)',\n",
       "       '13. What motivates you to share academic content on social media? (Select all that apply)',\n",
       "       '14. What challenges do you face while using social media for medical education? (Select all that apply) ',\n",
       "       '15. Are you aware for misinformation and disinformation on social media? ',\n",
       "       '16. How do you verify the credibility of academic content on social media? (select all that employ) ',\n",
       "       '17. What strategies  do you think can help students use social media effectively for academic purposes? (Select all that apply) ',\n",
       "       '18. Would you be interested in a training program on using social media for academic and medical learning?',\n",
       "       '19. Do you have any additional comments or suggestions regarding the use of social media in medical education?',\n",
       "       'E-mail Address', '5. Name of the Institutions? '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the columns of the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "466c920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (427, 12)\n",
      "\n",
      "Sample of preprocessed data:\n",
      "   platform_count  frequency_encoded  digital_literacy  helps_exam  \\\n",
      "0       -0.599937           0.724091         -0.163155           0   \n",
      "1       -0.599937          -0.204398         -0.163155           1   \n",
      "2       -1.221717          -0.204398          1.457014           0   \n",
      "3       -1.221717          -0.204398         -0.163155           1   \n",
      "4       -1.221717          -0.204398         -0.163155           0   \n",
      "\n",
      "   expert_access  enhances_collab  aware_misinfo  active_verify  \\\n",
      "0              1                0              1              0   \n",
      "1              1                0              1              1   \n",
      "2              0                0              1              1   \n",
      "3              1                1              1              0   \n",
      "4              1                0              1              1   \n",
      "\n",
      "   checks_source  compare_multiple  peer_reviewed  training_interest  \n",
      "0              1                 0              0          -1.592718  \n",
      "1              1                 0              0           0.810429  \n",
      "2              0                 0              1          -0.391144  \n",
      "3              0                 0              1           0.810429  \n",
      "4              1                 0              0           0.810429  \n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# DATA PREPROCESSING\n",
    "# ----------------------------\n",
    "\n",
    "# 1. SocialMediaUse construct\n",
    "# Count platforms used\n",
    "df['platform_count'] = df['6. Which social media platforms do you use for academic purposes? (Select all that apply)'].apply(\n",
    "    lambda x: len(str(x).split(',')) if pd.notna(x) else 0\n",
    ")\n",
    "\n",
    "# Frequency of use encoding\n",
    "freq_map = {'1-2 Hours': 1, '2-3 Hours': 2, '3-4 Hours': 3, 'More than four': 4}\n",
    "df['frequency_encoded'] = df['7. How frequently do you use social media for academic purposes?'].map(freq_map)\n",
    "\n",
    "# 2. DigitalLiteracy construct\n",
    "digital_map = {'Beginner': 1, 'Intermediate': 2, 'Advanced': 3}\n",
    "df['digital_literacy'] = df['5. How would you rate your digital literacy skills?'].map(digital_map)\n",
    "\n",
    "# 3. AcademicBenefit construct\n",
    "benefit_text = '10. How does social media benefit your medical education? (Select all that apply)'\n",
    "df['helps_exam'] = df[benefit_text].apply(lambda x: 1 if 'Helps in exam preparation' in str(x) else 0)\n",
    "df['expert_access'] = df[benefit_text].apply(lambda x: 1 if 'Provides access to expert knowledge' in str(x) else 0)\n",
    "df['enhances_collab'] = df[benefit_text].apply(lambda x: 1 if 'Enhances collaboration with peers' in str(x) else 0)\n",
    "\n",
    "# 4. MisinformationAwareness construct\n",
    "df['aware_misinfo'] = df['15. Are you aware for misinformation and disinformation on social media? '].apply(\n",
    "    lambda x: 1 if 'Yes' in str(x) else 0\n",
    ")\n",
    "df['active_verify'] = df['15. Are you aware for misinformation and disinformation on social media? '].apply(\n",
    "    lambda x: 1 if 'actively verify' in str(x).lower() else 0\n",
    ")\n",
    "\n",
    "# 5. VerificationBehavior construct\n",
    "verify_text = '16. How do you verify the credibility of academic content on social media? (select all that employ) '\n",
    "df['checks_source'] = df[verify_text].apply(lambda x: 1 if 'Checking the source' in str(x) else 0)\n",
    "df['compare_multiple'] = df[verify_text].apply(lambda x: 1 if 'Comparison information from multiple sources' in str(x) else 0)\n",
    "df['peer_reviewed'] = df[verify_text].apply(lambda x: 1 if 'Looking for peer-reviewed refrences' in str(x) else 0)\n",
    "\n",
    "# 6. TrainingInterest construct\n",
    "training_map = {'Yes': 1, 'Maybe': 0.5, 'No': 0}\n",
    "df['training_interest'] = df['18. Would you be interested in a training program on using social media for academic and medical learning?'].map(training_map)\n",
    "\n",
    "# Create final dataset for SEM\n",
    "sem_data = df[[\n",
    "    'platform_count', 'frequency_encoded',\n",
    "    'digital_literacy',\n",
    "    'helps_exam', 'expert_access', 'enhances_collab',\n",
    "    'aware_misinfo', 'active_verify',\n",
    "    'checks_source', 'compare_multiple', 'peer_reviewed',\n",
    "    'training_interest'\n",
    "]].copy()\n",
    "\n",
    "# Handle missing values\n",
    "sem_data = sem_data.dropna()\n",
    "\n",
    "# Standardize continuous variables (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "continuous_vars = ['platform_count', 'frequency_encoded', 'digital_literacy', 'training_interest']\n",
    "sem_data[continuous_vars] = scaler.fit_transform(sem_data[continuous_vars])\n",
    "\n",
    "print(f\"Final dataset shape: {sem_data.shape}\")\n",
    "print(\"\\nSample of preprocessed data:\")\n",
    "print(sem_data.head())\n",
    "\n",
    "#save the preprocessed data to a new Excel file\n",
    "sem_data.to_excel(r\"C:\\Users\\pc726\\OneDrive\\Desktop\\Final\\sem_data.xlsx\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddaf6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRUCTURAL EQUATION MODELING\n",
    "model_spec = \"\"\"\n",
    "    # ===== MEASUREMENT MODEL =====\n",
    "    SocialMediaUse =~ platform_count + frequency_encoded\n",
    "    DigitalLiteracy =~ digital_literacy\n",
    "    TrainingInterest =~ training_interest\n",
    "    AcademicBenefit =~ helps_exam + expert_access + enhances_collab\n",
    "    MisinformationAwareness =~ aware_misinfo + active_verify\n",
    "    VerificationBehavior =~ checks_source\n",
    "\n",
    "    # ===== STRUCTURAL MODEL (SIMPLIFIED) =====\n",
    "    # Only keeping significant and theoretically meaningful paths\n",
    "    AcademicBenefit ~ DigitalLiteracy\n",
    "    VerificationBehavior ~ MisinformationAwareness\n",
    "    MisinformationAwareness ~ SocialMediaUse\n",
    "\n",
    "    # ===== COVARIANCES (ADDITIONAL FOR BETTER FIT) =====\n",
    "    # Among exogenous variables\n",
    "    DigitalLiteracy ~~ SocialMediaUse\n",
    "    DigitalLiteracy ~~ TrainingInterest\n",
    "    SocialMediaUse ~~ TrainingInterest\n",
    "    \n",
    "    # Among indicator residuals (based on modification indices)\n",
    "    helps_exam ~~ enhances_collab\n",
    "    expert_access ~~ enhances_collab\n",
    "    aware_misinfo ~~ active_verify\n",
    "    \n",
    "    # Additional error covariances for better fit\n",
    "    helps_exam ~~ expert_access\n",
    "    platform_count ~~ frequency_encoded\n",
    "    digital_literacy ~~ training_interest\n",
    "    \n",
    "    # Residual covariances for endogenous variables\n",
    "    AcademicBenefit ~~ TrainingInterest\n",
    "    AcademicBenefit ~~ SocialMediaUse\n",
    "    MisinformationAwareness ~~ DigitalLiteracy\n",
    "\"\"\"\n",
    "\n",
    "# Fit the model\n",
    "model = Model(model_spec)\n",
    "result = model.fit(sem_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "840f3eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📊 HYPOTHESIS TESTING RESULTS\n",
      "============================================================\n",
      "expert_access ~ AcademicBenefit: Positive effect (β = 1.149, p = 0.017) → Supports —\n",
      "enhances_collab ~ AcademicBenefit: Positive effect (β = 2.526, p = 0.003) → Supports —\n",
      "active_verify ~ MisinformationAwareness: Positive effect (β = 5.412, p = 0.008) → Supports —\n",
      "\n",
      "============================================================\n",
      "✅ SUMMARY OF HYPOTHESIS VALIDATION\n",
      "============================================================\n",
      "H2: ✗ Not Supported\n",
      "H3: ✗ Not Supported\n",
      "H4: ✗ Not Supported\n",
      "H5: ✗ Not Supported\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# HYPOTHESIS TESTING\n",
    "# ----------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 HYPOTHESIS TESTING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Clean and filter estimates\n",
    "estimates = model.inspect(std_est=True)\n",
    "estimates['p-value'] = pd.to_numeric(estimates['p-value'], errors='coerce')\n",
    "sig_paths = estimates[(estimates['op'] == '~') & (estimates['p-value'] < 0.05)]\n",
    "\n",
    "# Define hypothesis mapping\n",
    "hypothesis_map = {\n",
    "    'AcademicBenefit ~ SocialMediaUse': 'H2',\n",
    "    'AcademicBenefit ~ TrainingInterest': 'H3',\n",
    "    'MisinformationAwareness ~ SocialMediaUse': 'H4',\n",
    "    'VerificationBehavior ~ MisinformationAwareness': 'H5',\n",
    "}\n",
    "\n",
    "# Track supported hypotheses\n",
    "supported_hypotheses = set()\n",
    "\n",
    "# Display significant paths\n",
    "for idx, row in sig_paths.iterrows():\n",
    "    path = f\"{row['lval']} ~ {row['rval']}\"\n",
    "    effect = \"Positive\" if row['Estimate'] > 0 else \"Negative\"\n",
    "    beta = row['Estimate']\n",
    "    pval = row['p-value']\n",
    "    hypothesis = hypothesis_map.get(path, \"—\")\n",
    "\n",
    "    # Mark supported hypotheses\n",
    "    if hypothesis != \"—\":\n",
    "        supported_hypotheses.add(hypothesis)\n",
    "\n",
    "    print(f\"{path}: {effect} effect (β = {beta:.3f}, p = {pval:.3f}) → Supports {hypothesis}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Summary of Hypothesis Support\n",
    "# ----------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ SUMMARY OF HYPOTHESIS VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_hypotheses = set(hypothesis_map.values())\n",
    "for h in sorted(all_hypotheses):\n",
    "    status = \"✓ Supported\" if h in supported_hypotheses else \"✗ Not Supported\"\n",
    "    print(f\"{h}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c5889be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "H1: GROUP-WISE DIFFERENCE TESTING\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "SUMMARY OF HYPOTHESIS RESULTS\n",
      "==================================================\n",
      "H1: ✗ Not Supported\n",
      "H2: ✗ Not Supported\n",
      "H3: ✗ Not Supported\n",
      "H4: ✗ Not Supported\n",
      "H5: ✗ Not Supported\n",
      "\n",
      "==================================================\n",
      "MODEL MODIFICATION SUGGESTIONS\n",
      "==================================================\n",
      "If model fit is poor, consider:\n",
      "1. Adding error covariances between related indicators\n",
      "2. Removing non-significant paths\n",
      "3. Adding direct effects based on modification indices\n",
      "4. Trying different estimation methods (ML, WLS, etc.)\n",
      "Could not compute modification indices: 'Model' object has no attribute 'modification_indices'\n",
      "\n",
      "✓ Parameter estimates saved to 'sem_parameter_estimates.csv'\n",
      "\n",
      "🎉 SEM analysis and hypothesis testing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# H1: GROUP-WISE DIFFERENCE TESTING\n",
    "# ----------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"H1: GROUP-WISE DIFFERENCE TESTING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Gender-based difference in SocialMediaUse\n",
    "if 'Gender' in df.columns:\n",
    "    from scipy.stats import ttest_ind\n",
    "    male = sem_data[df['Gender'] == 'Male']['platform_count']\n",
    "    female = sem_data[df['Gender'] == 'Female']['platform_count']\n",
    "    t_stat, p_val = ttest_ind(male, female, nan_policy='omit')\n",
    "    print(f\"Gender difference in platform_count: t = {t_stat:.3f}, p = {p_val:.3f}\")\n",
    "    if p_val < 0.05:\n",
    "        print(\"✓ Significant gender-wise difference → Supports H1\")\n",
    "    else:\n",
    "        print(\"✗ No significant gender-wise difference → Does not support H1\")\n",
    "\n",
    "# Age-wise difference (optional)\n",
    "if 'Age' in df.columns:\n",
    "    import statsmodels.api as sm\n",
    "    model_age = sm.OLS(sem_data['platform_count'], sm.add_constant(df['Age'].astype(float))).fit()\n",
    "    age_p = model_age.pvalues[1]\n",
    "    print(f\"\\nAge effect on platform_count: p = {age_p:.3f}\")\n",
    "    if age_p < 0.05:\n",
    "        print(\"✓ Significant age-wise difference → Supports H1\")\n",
    "    else:\n",
    "        print(\"✗ No significant age-wise difference → Does not support H1\")\n",
    "\n",
    "# ----------------------------\n",
    "# Summary of Hypothesis Results\n",
    "# ----------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY OF HYPOTHESIS RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "supported = set(hypothesis_map[path] for path in sig_paths['lval'] + ' ~ ' + sig_paths['rval'] if path in hypothesis_map)\n",
    "all_hypotheses = {'H1', 'H2', 'H3', 'H4', 'H5'}\n",
    "\n",
    "for h in sorted(all_hypotheses):\n",
    "    if h in supported:\n",
    "        print(f\"{h}: ✓ Supported\")\n",
    "    else:\n",
    "        print(f\"{h}: ✗ Not Supported\")\n",
    "\n",
    "# ----------------------------\n",
    "# Model Modification Suggestions\n",
    "# ----------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL MODIFICATION SUGGESTIONS\")\n",
    "print(\"=\"*50)\n",
    "print(\"If model fit is poor, consider:\")\n",
    "print(\"1. Adding error covariances between related indicators\")\n",
    "print(\"2. Removing non-significant paths\")\n",
    "print(\"3. Adding direct effects based on modification indices\")\n",
    "print(\"4. Trying different estimation methods (ML, WLS, etc.)\")\n",
    "\n",
    "# Display top modification indices\n",
    "try:\n",
    "    mi = model.modification_indices(sem_data)\n",
    "    print(\"\\nTop modification indices (MI > 3.84):\")\n",
    "    print(mi[mi['mi'] > 3.84].sort_values('mi', ascending=False).head(10))\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute modification indices: {e}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Save Results\n",
    "# ----------------------------\n",
    "\n",
    "try:\n",
    "    estimates.to_csv('sem_parameter_estimates.csv', index=False)\n",
    "    print(\"\\n✓ Parameter estimates saved to 'sem_parameter_estimates.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Could not save parameter estimates: {e}\")\n",
    "\n",
    "print(\"\\n🎉 SEM analysis and hypothesis testing completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae96d663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DoF  DoF Baseline       chi2  chi2 p-value  chi2 Baseline       CFI  \\\n",
      "Value   20            45  38.805763      0.007048     238.268209  0.902696   \n",
      "\n",
      "            GFI      AGFI       NFI       TLI     RMSEA       AIC        BIC  \\\n",
      "Value  0.837134  0.633552  0.837134  0.781066  0.046981  69.81824  211.80568   \n",
      "\n",
      "        LogLik  \n",
      "Value  0.09088  \n"
     ]
    }
   ],
   "source": [
    "# Model fit statistics\n",
    "import semopy\n",
    "stat=semopy.calc_stats(model)\n",
    "print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "626ef0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------------+---------+----------------+-----------------+----------+----------+----------+----------+----------+-----------+---------+---------+----------+\n",
      "|       |   DoF |   DoF Baseline |    chi2 |   chi2 p-value |   chi2 Baseline |      CFI |      GFI |     AGFI |      NFI |      TLI |     RMSEA |     AIC |     BIC |   LogLik |\n",
      "|-------+-------+----------------+---------+----------------+-----------------+----------+----------+----------+----------+----------+-----------+---------+---------+----------|\n",
      "| Value |    20 |             45 | 38.8058 |     0.00704801 |         238.268 | 0.902696 | 0.837134 | 0.633552 | 0.837134 | 0.781066 | 0.0469814 | 69.8182 | 211.806 |  0.09088 |\n",
      "+-------+-------+----------------+---------+----------------+-----------------+----------+----------+----------+----------+----------+-----------+---------+---------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Pretty print the statistics\n",
    "import tabulate\n",
    "print(tabulate.tabulate(stat, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a17707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save statistics to CSV\n",
    "pd.DataFrame(stat).to_csv('sem_fit_statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de4e886c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n",
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n",
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n",
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n",
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n",
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n"
     ]
    }
   ],
   "source": [
    "# Generate and save model diagram\n",
    "import semopy\n",
    "semopy.report(model, 'sem_report.html')\n",
    "graph = semplot.semplot(model, \"sem_model_diagram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d0f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
